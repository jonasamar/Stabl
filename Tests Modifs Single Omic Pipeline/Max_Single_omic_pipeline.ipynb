{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LassoCV, LogisticRegressionCV, LogisticRegression, LinearRegression, ElasticNetCV,\\\n",
    "    Lasso\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, RepeatedKFold, LeaveOneOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import l1_min_c\n",
    "\n",
    "from stabl.metrics import jaccard_matrix\n",
    "from stabl.preprocessing import LowInfoFilter, remove_low_info_samples\n",
    "from stabl.stabl import save_stabl_results\n",
    "from stabl.visualization import boxplot_features\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "from stabl.pipelines_utils import save_plots, compute_scores_table\n",
    "\n",
    "lasso = Lasso(max_iter=int(1e6))\n",
    "lasso_cv = LassoCV(n_alphas=50, max_iter=int(1e6), n_jobs=-1)\n",
    "en_cv = ElasticNetCV(n_alphas=50, max_iter=int(1e6), n_jobs=-1, l1_ratio=.5)\n",
    "\n",
    "logit_lasso_cv = LogisticRegressionCV(penalty=\"l1\", solver=\"liblinear\", Cs=np.logspace(-2, 2, 50),\n",
    "                                      max_iter=int(1e6), class_weight=\"balanced\", scoring=\"roc_auc\",\n",
    "                                      n_jobs=-1\n",
    "                                      )\n",
    "\n",
    "logit_en_cv = LogisticRegressionCV(penalty=\"elasticnet\", solver=\"saga\", Cs=np.logspace(-2, 2, 50),\n",
    "                                   max_iter=int(1e6), class_weight=\"balanced\", scoring=\"roc_auc\",\n",
    "                                   n_jobs=-1, l1_ratios=[.5]\n",
    "                                   )\n",
    "\n",
    "logit = LogisticRegression(penalty=None, class_weight=\"balanced\", max_iter=int(1e6))\n",
    "linreg = LinearRegression()\n",
    "\n",
    "preprocessing = Pipeline(\n",
    "    steps=[\n",
    "        (\"variance\", VarianceThreshold(0.01)),\n",
    "        (\"lif\", LowInfoFilter()),\n",
    "        (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"std\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def new_single_omic_stabl_cv(\n",
    "        X,\n",
    "        y,\n",
    "        outer_splitter,\n",
    "        stablList,\n",
    "        stabl_names,\n",
    "        stability_selection,\n",
    "        task_type,\n",
    "        save_path,\n",
    "        outer_groups=None\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X\n",
    "    stability_selection: Stabl\n",
    "    data_dict: dict\n",
    "        Dictionary containing the input omic-files.\n",
    "\n",
    "    y: pd.Series\n",
    "        pandas Series containing the outcomes for the use case. Note that y should contains the union of outcomes for\n",
    "        the data_dict.\n",
    "\n",
    "    outer_splitter: sklearn.model_selection._split.BaseCrossValidator\n",
    "        Outer cross validation splitter\n",
    "\n",
    "    stablList: list of SurgeLibrary.stability_selection.StabilitySelection\n",
    "        list of the STABL used to select features at each fold of the cross validation and for each omic.\n",
    "        \n",
    "    stabl_names: list of str\n",
    "        list of the names of the STABL used to select features at each fold of the cross validation and for each omic.\n",
    "        THEY HAVE TO BE IN THE SAME ORDER AS IN THE VARIABLE stabl\n",
    "\n",
    "    task_type: str\n",
    "        Can either be \"binary\" for binary classification or \"regression\" for regression tasks.\n",
    "\n",
    "    save_path: Path or str\n",
    "        Where to save the results\n",
    "\n",
    "    outer_groups: pd.Series, default=None\n",
    "        If used, should be the same size as y and should indicate the groups of the samples.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    models = [\"SS 03\", \"SS 05\", \"SS 08\", \"Lasso\", \"Lasso 1SE\", \"ElasticNet\"] + stabl_names\n",
    "\n",
    "    os.makedirs(Path(save_path, \"Training CV\"), exist_ok=True)\n",
    "    os.makedirs(Path(save_path, \"Summary\"), exist_ok=True)\n",
    "\n",
    "    # Initializing the df containing the data of all omics\n",
    "    predictions_dict = dict()\n",
    "    selected_features_dict = dict()\n",
    "\n",
    "    for model in models:\n",
    "        predictions_dict[model] = pd.DataFrame(data=None, index=y.index)\n",
    "        selected_features_dict[model] = []\n",
    "\n",
    "    i = 1\n",
    "    for train, test in outer_splitter.split(X, y, groups=outer_groups):\n",
    "        # Jonas additional code in case outer_splitter is LeaveOneOut\n",
    "        if isinstance(outer_splitter, LeaveOneOut):\n",
    "            print(f\" Iteration {i} over {X.shape[0]} \".center(80, '*'), \"\\n\")\n",
    "        else:\n",
    "            print(f\" Iteration {i} over {outer_splitter.get_n_splits()} \".center(80, '*'), \"\\n\")\n",
    "        # end additional code\n",
    "        train_idx, test_idx = y.iloc[train].index, y.iloc[test].index\n",
    "\n",
    "        fold_selected_features = dict()\n",
    "        for model in models:\n",
    "            fold_selected_features[model] = []\n",
    "\n",
    "        print(f\"{len(train_idx)} train samples, {len(test_idx)} test samples\")\n",
    "\n",
    "        X_tmp = X.drop(index=test_idx, errors=\"ignore\")\n",
    "\n",
    "        # Preprocessing of X_tmp\n",
    "        X_tmp = remove_low_info_samples(X_tmp)\n",
    "        y_tmp = y.loc[X_tmp.index]\n",
    "\n",
    "        X_tmp_std = pd.DataFrame(\n",
    "            data=preprocessing.fit_transform(X_tmp),\n",
    "            index=X_tmp.index,\n",
    "            columns=preprocessing.get_feature_names_out()\n",
    "        )\n",
    "\n",
    "        # __STABL__\n",
    "        if task_type == \"binary\":\n",
    "            min_C = l1_min_c(X_tmp_std, y_tmp)\n",
    "            lambda_grid = np.linspace(min_C, min_C * 100, 10)\n",
    "            stability_selection.set_params(lambda_grid=lambda_grid)\n",
    "            for id, stabl_model in enumerate(stablList):\n",
    "                stabl_model.set_params(lambda_grid=lambda_grid)\n",
    "                stabl_model.fit(X_tmp_std, y_tmp)\n",
    "                tmp_sel_features = list(stabl_model.get_feature_names_out())\n",
    "                fold_selected_features[stabl_names[id]] = tmp_sel_features\n",
    "                print(\n",
    "                    f\"{stabl_names[id]} finished ({X_tmp.shape[0]} samples);\"\n",
    "                    f\" {len(tmp_sel_features)} features selected\\n\"\n",
    "                )\n",
    "\n",
    "        # __SS__\n",
    "        stability_selection.fit(X_tmp_std, y_tmp)\n",
    "        fold_selected_features[\"SS 03\"] = list(stability_selection.get_feature_names_out(new_hard_threshold=.3))\n",
    "        fold_selected_features[\"SS 05\"] = list(stability_selection.get_feature_names_out(new_hard_threshold=.5))\n",
    "        fold_selected_features[\"SS 08\"] = list(stability_selection.get_feature_names_out(new_hard_threshold=.8))\n",
    "\n",
    "        selected_features_dict[\"STABL\"].append(fold_selected_features[\"STABL\"])\n",
    "        selected_features_dict[f\"SS 03\"].append(fold_selected_features[\"SS 03\"])\n",
    "        selected_features_dict[f\"SS 05\"].append(fold_selected_features[\"SS 05\"])\n",
    "        selected_features_dict[f\"SS 08\"].append(fold_selected_features[\"SS 08\"])\n",
    "\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "        print(f\"This fold: {len(fold_selected_features['STABL'])} features selected for STABL\")\n",
    "        print(f\"This fold: {len(fold_selected_features['SS 03'])} features selected for SS 03\")\n",
    "        print(f\"This fold: {len(fold_selected_features['SS 05'])} features selected for SS 05\")\n",
    "        print(f\"This fold: {len(fold_selected_features['SS 08'])} features selected for SS 08\")\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\")\n",
    "\n",
    "        for model in stabl_names + [\"SS 03\", \"SS 05\", \"SS 08\"]:\n",
    "\n",
    "            X_train = X.loc[train_idx, fold_selected_features[model]]\n",
    "            X_test = X.loc[test_idx, fold_selected_features[model]]\n",
    "            y_train, y_test = y.loc[train_idx], y.loc[test_idx]\n",
    "\n",
    "            if len(fold_selected_features[model]) > 0:\n",
    "                # Standardization\n",
    "                std_pipe = Pipeline(\n",
    "                    steps=[\n",
    "                        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "                        ('std', StandardScaler())\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                X_train = pd.DataFrame(\n",
    "                    data=std_pipe.fit_transform(X_train),\n",
    "                    index=X_train.index,\n",
    "                    columns=X_train.columns\n",
    "                )\n",
    "                X_test = pd.DataFrame(\n",
    "                    data=std_pipe.transform(X_test),\n",
    "                    index=X_test.index,\n",
    "                    columns=X_test.columns\n",
    "                )\n",
    "\n",
    "                # __Final Models__\n",
    "                if task_type == \"binary\":\n",
    "                    predictions = clone(logit).fit(X_train, y_train).predict_proba(X_test)[:, 1].flatten()\n",
    "\n",
    "                elif task_type == \"regression\":\n",
    "                    predictions = clone(linreg).fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(\"task_type not recognized.\")\n",
    "\n",
    "                predictions_dict[model].loc[test_idx, f'Fold n°{i}'] = predictions\n",
    "\n",
    "            else:\n",
    "                if task_type == \"binary\":\n",
    "                    predictions_dict[model].loc[test_idx, f'Fold n°{i}'] = [0.5] * len(test_idx)\n",
    "\n",
    "                elif task_type == \"regression\":\n",
    "                    predictions_dict[model].loc[test_idx, f'Fold n°{i}'] = [np.mean(y_train)] * len(test_idx)\n",
    "\n",
    "                else:\n",
    "                    raise ValueError(\"task_type not recognized.\")\n",
    "\n",
    "        # __other models__\n",
    "        X_train = X.loc[train_idx]\n",
    "        X_test = X.loc[test_idx]\n",
    "        X_train = pd.DataFrame(\n",
    "            data=preprocessing.fit_transform(X_train),\n",
    "            columns=preprocessing.get_feature_names_out(),\n",
    "            index=X_train.index\n",
    "        )\n",
    "\n",
    "        X_test = pd.DataFrame(\n",
    "            data=preprocessing.transform(X_test),\n",
    "            columns=preprocessing.get_feature_names_out(),\n",
    "            index=X_test.index\n",
    "        )\n",
    "\n",
    "        # __Lasso__\n",
    "        if task_type == \"binary\":\n",
    "            inner_splitter = RepeatedStratifiedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "            model = clone(logit_lasso_cv).set_params(cv=inner_splitter)\n",
    "            predictions = model.fit(X_train, y_train).predict_proba(X_test)[:, 1]\n",
    "        else:\n",
    "            inner_splitter = RepeatedKFold(n_splits=5, n_repeats=5, random_state=42)\n",
    "            model = clone(lasso_cv).set_params(cv=inner_splitter)\n",
    "            predictions = model.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "        selected_features_dict[\"Lasso\"].append(list(X_train.columns[np.where(model.coef_.flatten())]))\n",
    "        predictions_dict[\"Lasso\"].loc[test_idx, f\"Fold n°{i}\"] = predictions\n",
    "\n",
    "        # __Lasso 1SE__\n",
    "        if task_type == \"binary\":\n",
    "            new_best_c_corr = model.C_[0] - model.scores_[True].std() / np.sqrt(inner_splitter.get_n_splits())\n",
    "            if new_best_c_corr < 0:\n",
    "                best_c_corr = abs(model.C_[0])\n",
    "            else:\n",
    "                best_c_corr = new_best_c_corr\n",
    "            model = LogisticRegression(penalty='l1', solver='liblinear', C=best_c_corr, class_weight='balanced',\n",
    "                                       max_iter=2_000_000)\n",
    "            predictions = model.fit(X_train, y_train).predict_proba(X_test)[:, 1]\n",
    "\n",
    "        selected_features_dict[\"Lasso 1SE\"].append(list(X_train.columns[np.where(model.coef_.flatten())]))\n",
    "        predictions_dict[\"Lasso 1SE\"].loc[test_idx, f\"Fold n°{i}\"] = predictions\n",
    "\n",
    "        # __EN__\n",
    "        if task_type == \"binary\":\n",
    "            model = clone(logit_en_cv).set_params(cv=inner_splitter)\n",
    "            predictions = model.fit(X_train, y_train).predict_proba(X_test)[:, 1]\n",
    "\n",
    "        else:\n",
    "            model = clone(en_cv).set_params(cv=inner_splitter)\n",
    "            predictions = model.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "        selected_features_dict[\"ElasticNet\"].append(list(X_train.columns[np.where(model.coef_.flatten())]))\n",
    "        predictions_dict[\"ElasticNet\"].loc[test_idx, f\"Fold n°{i}\"] = predictions\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # __SAVING_RESULTS__\n",
    "\n",
    "    if y.name is None:\n",
    "        y.name = \"outcome\"\n",
    "\n",
    "    summary_res_path = Path(save_path, \"Summary\")\n",
    "    cv_res_path = Path(save_path, \"Training CV\")\n",
    "\n",
    "    jaccard_matrix_dict = dict()\n",
    "    formatted_features_dict = dict()\n",
    "\n",
    "    for model in models:\n",
    "\n",
    "        jaccard_matrix_dict[model] = jaccard_matrix(selected_features_dict[model])\n",
    "        \n",
    "        # Jonas additional code in case outer_splitter is LeaveOneOut\n",
    "        if isinstance(outer_splitter, LeaveOneOut):\n",
    "            index=[f\"Fold {i}\" for i in range(X.shape[0])]\n",
    "        else:\n",
    "            index=[f\"Fold {i}\" for i in range(outer_splitter.get_n_splits())]\n",
    "        # end additional code\n",
    "\n",
    "        formatted_features_dict[model] = pd.DataFrame(\n",
    "            data={\n",
    "                \"Fold selected features\": selected_features_dict[model],\n",
    "                \"Fold nb of features\": [len(el) for el in selected_features_dict[model]]\n",
    "            },\n",
    "            index=index # Jonas'additional code linked to this parameter\n",
    "        )\n",
    "        formatted_features_dict[model].to_csv(Path(cv_res_path, f\"Selected Features {model}.csv\"))\n",
    "\n",
    "    predictions_dict = {model: predictions_dict[model].median(axis=1) for model in predictions_dict.keys()}\n",
    "\n",
    "    table_of_scores = compute_scores_table(\n",
    "        predictions_dict=predictions_dict,\n",
    "        y=y,\n",
    "        task_type=task_type,\n",
    "        selected_features_dict=formatted_features_dict\n",
    "    )\n",
    "\n",
    "    table_of_scores.to_csv(Path(summary_res_path, \"Scores training CV.csv\"))\n",
    "    table_of_scores.to_csv(Path(cv_res_path, \"Scores training CV.csv\"))\n",
    "\n",
    "    save_plots(\n",
    "        predictions_dict=predictions_dict,\n",
    "        y=y,\n",
    "        task_type=task_type,\n",
    "        save_path=cv_res_path\n",
    "    )\n",
    "    \n",
    "    # Univariate Analysis\n",
    "    \n",
    "    if task_type == 'binary':\n",
    "        resultFolderUnivariate = save_path+\"/Univariate/\"\n",
    "        \n",
    "        vals1 = []\n",
    "        vals2 = []\n",
    "        for col in X.columns:\n",
    "            a,b = mannwhitneyu(X.loc[y == 0,col].to_numpy(),X.loc[y == 1,col].to_numpy())\n",
    "            vals1.append(a)\n",
    "            vals2.append(b)\n",
    "            \n",
    "        res = pd.DataFrame(data=[vals1,vals2],index= [\"Mann-Whitney U-test\",\"p-value\"],columns=X.columns)\n",
    "        res = res.sort_values(by=\"p-value\",axis=1)\n",
    "        res.T.to_csv(Path(resultFolderUnivariate + \"Mann-WhitneyU-testPval.csv\"))\n",
    "            \n",
    "\n",
    "        boxplot_features(\n",
    "            list_of_features=res.columns[:10],\n",
    "            df_X=X[res.columns[:10]],\n",
    "            y=y,\n",
    "            show_fig=False,\n",
    "            export_file=True,\n",
    "            path = Path(resultFolderUnivariate)\n",
    "            )\n",
    "    \n",
    "        # Final STABL\n",
    "        \n",
    "        preprocessing2 = Pipeline(\n",
    "        steps=[\n",
    "            (\"lif\", LowInfoFilter(0.2)),\n",
    "            (\"variance\", VarianceThreshold(0.01)),\n",
    "            (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"std\", StandardScaler())\n",
    "        ]\n",
    "        )\n",
    "\n",
    "        dataSTD = pd.DataFrame(\n",
    "            data=preprocessing2.fit_transform(X),\n",
    "            index=X.index,\n",
    "            columns=preprocessing2.get_feature_names_out()\n",
    "        )\n",
    "        \n",
    "        for id, stabl_model in enumerate(stablList):\n",
    "            stabl = clone(stabl_model)\n",
    "            stabl.fit(dataSTD,y.astype(int))\n",
    "\n",
    "            resultFolder = save_path + stabl_names[id]\n",
    "            save_stabl_results(stabl_model,resultFolder+\"/FinalSTABL/\"+stabl_names[id],dataSTD,y,task_type=\"binary\")\n",
    "\n",
    "    return predictions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from stabl.preprocessing import LowInfoFilter\n",
    "from stabl.stabl import Stabl, save_stabl_results\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import Lasso,ElasticNet,LogisticRegression\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from scipy.stats import mannwhitneyu\n",
    "from stabl.visualization import scatterplot_features,boxplot_features\n",
    "from stabl.single_omic_pipelines import single_omic_stabl, single_omic_stabl_cv\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# lasso = Lasso(max_iter=int(1e6))\n",
    "# en05_05 = ElasticNet(max_iter=int(1e6))\n",
    "\n",
    "# stabl_regression = Stabl(\n",
    "#     base_estimator=clone(lasso),\n",
    "#     lambda_grid=np.logspace(0.01, 2, 30),\n",
    "#     lambda_name=\"alpha\",\n",
    "#     artificial_type=\"knockoff\",\n",
    "#     artificial_proportion=1,\n",
    "#     n_bootstraps=1000,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "logit_lasso = LogisticRegression(penalty=\"l1\", max_iter=int(1e6), solver=\"liblinear\", class_weight=\"balanced\")\n",
    "logit_en05 = LogisticRegression(penalty=\"elasticnet\", l1_ratio = 0.5, max_iter=int(1e6), solver=\"saga\", class_weight=\"balanced\")\n",
    "\n",
    "stabl_class = Stabl(\n",
    "    base_estimator=clone(logit_lasso),\n",
    "    lambda_name=\"C\",\n",
    "    lambda_grid=np.linspace(0.01, 1, 30),\n",
    "    artificial_type=\"knockoff\",\n",
    "    fdr_threshold_range=np.arange(0.1, 1, 0.01),\n",
    "    n_bootstraps=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "stablList = [clone(stabl_class),clone(stabl_class).set_params(artificial_type=\"random_permutation\"),\n",
    "             clone(stabl_class).set_params(base_estimator=clone(logit_en05)),\n",
    "             clone(stabl_class).set_params(base_estimator=clone(logit_en05),artificial_type=\"random_permutation\")]\n",
    "stablNames = [\"L-KF\",\"L-RP\",\"EN05-KF\",\"EN05-RP\"]\n",
    "\n",
    "#outer_splitter = LeaveOneOut()\n",
    "outer_splitter = RepeatedStratifiedKFold(n_splits=5, n_repeats=4, random_state=42)\n",
    "\n",
    "stability_selection = clone(stabl_class).set_params(artificial_type=None, hard_threshold=0.3)\n",
    "\n",
    "\n",
    "def run():\n",
    "    X_train = pd.read_csv('../Sample Data/COVID-19/Training/Proteomics.csv',index_col=\"sampleID\")\n",
    "    X_val = pd.read_csv(\"../Sample Data/COVID-19/Validation/Validation_proteomics.csv\", index_col=0)\n",
    "    y_val = pd.read_csv(\"../Sample Data/COVID-19/Validation/Validation_outcome(WHO.0 ≥ 5).csv\", index_col=0).iloc[:,0]\n",
    "    y_train = pd.read_csv(\"../Sample Data/COVID-19/Training/Mild&ModVsSevere.csv\", index_col=0).iloc[:, 0]\n",
    "        \n",
    "    data = pd.concat([X_train, X_val])\n",
    "    label = pd.concat([y_train, y_val])\n",
    "\n",
    "    new_single_omic_stabl_cv(\n",
    "    X=X_train,\n",
    "    y=y_train.astype(int),\n",
    "    outer_splitter=outer_splitter,\n",
    "    stablList=stablList,\n",
    "    stabl_names=stablNames,\n",
    "    stability_selection=stability_selection,\n",
    "    task_type=\"binary\",\n",
    "    save_path='./Results',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************** Iteration 1 over 20 ****************************** \n",
      "\n",
      "54 train samples, 14 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               34<00:00,  8.55s/it]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-KF finished (54 samples); 0 features selected\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               17<00:00,  7.97s/it]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L-RP finished (54 samples); 4 features selected\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   <00:00, 3285.43s/it] \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN05-KF finished (54 samples); 3 features selected\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   <00:00, 2900.47s/it] \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN05-RP finished (54 samples); 6 features selected\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               36<00:00,  3.72s/it]\r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'STABL'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m run()\n",
      "Cell \u001b[0;32mIn[33], line 65\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([X_train, X_val])\n\u001b[1;32m     63\u001b[0m label \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([y_train, y_val])\n\u001b[0;32m---> 65\u001b[0m new_single_omic_stabl_cv(\n\u001b[1;32m     66\u001b[0m X\u001b[39m=\u001b[39;49mX_train,\n\u001b[1;32m     67\u001b[0m y\u001b[39m=\u001b[39;49my_train\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m),\n\u001b[1;32m     68\u001b[0m outer_splitter\u001b[39m=\u001b[39;49mouter_splitter,\n\u001b[1;32m     69\u001b[0m stablList\u001b[39m=\u001b[39;49mstablList,\n\u001b[1;32m     70\u001b[0m stabl_names\u001b[39m=\u001b[39;49mstablNames,\n\u001b[1;32m     71\u001b[0m stability_selection\u001b[39m=\u001b[39;49mstability_selection,\n\u001b[1;32m     72\u001b[0m task_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbinary\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     73\u001b[0m save_path\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./Results\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     74\u001b[0m )\n",
      "Cell \u001b[0;32mIn[32], line 162\u001b[0m, in \u001b[0;36mnew_single_omic_stabl_cv\u001b[0;34m(X, y, outer_splitter, stablList, stabl_names, stability_selection, task_type, save_path, outer_groups)\u001b[0m\n\u001b[1;32m    159\u001b[0m fold_selected_features[\u001b[39m\"\u001b[39m\u001b[39mSS 05\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(stability_selection\u001b[39m.\u001b[39mget_feature_names_out(new_hard_threshold\u001b[39m=\u001b[39m\u001b[39m.5\u001b[39m))\n\u001b[1;32m    160\u001b[0m fold_selected_features[\u001b[39m\"\u001b[39m\u001b[39mSS 08\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(stability_selection\u001b[39m.\u001b[39mget_feature_names_out(new_hard_threshold\u001b[39m=\u001b[39m\u001b[39m.8\u001b[39m))\n\u001b[0;32m--> 162\u001b[0m selected_features_dict[\u001b[39m\"\u001b[39;49m\u001b[39mSTABL\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mappend(fold_selected_features[\u001b[39m\"\u001b[39m\u001b[39mSTABL\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    163\u001b[0m selected_features_dict[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSS 03\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(fold_selected_features[\u001b[39m\"\u001b[39m\u001b[39mSS 03\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    164\u001b[0m selected_features_dict[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSS 05\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(fold_selected_features[\u001b[39m\"\u001b[39m\u001b[39mSS 05\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'STABL'"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
