{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608746f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e00392e",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd2f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from stabl.stabl import Stabl, plot_stabl_path, plot_fdr_graph, export_stabl_to_csv, save_stabl_results\n",
    "from stabl.preprocessing import LowInfoFilter\n",
    "from stabl.visualization import boxplot_features, scatterplot_features\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import clone\n",
    "\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "\n",
    "%config InlineBackend.figure_formats=['retina'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0419d9ac",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a3c180",
   "metadata": {},
   "source": [
    "We define here the sparse models that will be used in the bootstrap process of Stabl:\n",
    "* In the regression case, we use the classic Lasso,\n",
    "* In the binary classification case, we use the Logistic Regression with l1 penalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f169f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(max_iter=int(1e6))\n",
    "logit_lasso = LogisticRegression(penalty=\"l1\", max_iter=int(1e6), solver=\"liblinear\", class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa93b272",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cadf52a",
   "metadata": {},
   "source": [
    "## Regression case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88646b89",
   "metadata": {},
   "source": [
    "For the regression case, we will use the Onset of Labor use case:\n",
    "* CyTOF layer\n",
    "* Proteomics layer\n",
    "* Metabolomics layer\n",
    "\n",
    "The outcome is the onset of labor (in days before labor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8752566b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_ool = pd.read_csv(\"../Sample Data/Onset of Labor/Training/Proteomics.csv\", index_col=0)\n",
    "meta_ool = pd.read_csv(\"../Sample Data/Onset of Labor/Training/Metabolomics.csv\", index_col=0)\n",
    "cyto_ool = pd.read_csv(\"../Sample Data/Onset of Labor/Training/CyTOF.csv\", index_col=0)\n",
    "\n",
    "DOS_ool = pd.read_csv(\"../Sample Data/Onset of Labor/Training/DOS.csv\", index_col=0).DOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd5b14d",
   "metadata": {},
   "source": [
    "## Binary classification case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52199751",
   "metadata": {},
   "source": [
    "For the binary classification case, we will use the COVID-19 use case:\n",
    "* Proteomics Layer\n",
    "\n",
    "The outcome is binary (0 = Mild or Moderate COVID and 1 = Severe COVID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a76a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_covid = pd.read_csv(\"../Sample Data/COVID-19/Training/Proteomics.csv\", index_col=0)\n",
    "covid_pos = pd.read_csv(\"../Sample Data/COVID-19/Training/Mild&ModVsSevere.csv\", index_col=0)[\"Mild&ModVsSevere\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7451ea2",
   "metadata": {},
   "source": [
    "# LowInfoFilter preprocessing object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc7a547",
   "metadata": {},
   "source": [
    "The goal of the class is to filter out the features whose nan proportion is above a defined threshold.\n",
    "\n",
    "We chose the class format rather than the function one as we'd like to have and object, acting as a scikit-learn preprocessing object, usable whitin a python scikit-learn Pipeline object. As a reference here is the [`VarianceThreshold`](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html?highlight=variance%20threshold#sklearn.feature_selection.VarianceThreshold) description. \n",
    "\n",
    "The `LowInfoFilter` inherits the same super classes as this very useful object and therefore, we have access to the same useful arguments such as `n_features_in_` and `feature_names_in_` allowing us to access the number of feature and the names of the features seen during the training. We can also access the names of the features that were selected by the filter using the `get_feature_names_out()`\n",
    "\n",
    "The LowInfoFilter class only has one parameter: `max_nan_fraction` acting as in the `remove_low_info_samples` function. The default value for the parameter is 0.2 (removing features having more than 20% of missing values).\n",
    "\n",
    "Inheriting from scikit-learn classes makes our filtering class injectable in a scikit-learn pipeline. This is very useful if we want to stack multiple preprocessing tasks, or when we want to evaluate the model in cross validation with the preprocessing done at each fold."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35451081",
   "metadata": {},
   "source": [
    "We will apply the typical preprocessing pipeline:\n",
    "* **VarianceThreshold**: typical variance threshold preprocessing\n",
    "* **LowInfoFilter**: Custom class developped for Biomics\n",
    "* **SimpleImputer**: see the doc here [`SimpleImputer`](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html?highlight=simple%20imputer#sklearn.impute.SimpleImputer). Useful to impute missing values.\n",
    "* **StandardScaler**: see the doc here [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html?highlight=standardscaler#sklearn.preprocessing.StandardScaler). Classic Z-score (standardization of the data: remove the mean and divide by the standard deviation)\n",
    "\n",
    "see the doc for scikit-learn [`Pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html?highlight=pipeline#sklearn.pipeline.Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4877372f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Pipeline(\n",
    "    steps=[\n",
    "        (\"variance_threshold\", VarianceThreshold(threshold=0)),\n",
    "        (\"low_info_filter\", LowInfoFilter(max_nan_fraction=0.2)),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"std\", StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2d02d1",
   "metadata": {},
   "source": [
    "# STABL in single-omic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7141d3c",
   "metadata": {},
   "source": [
    "To begin with, let's talk about the STABL class\n",
    "The class inherits from scikit-learn classes and make it compatible with scikit-learn functions.\n",
    "\n",
    "Particularly, we can use it in a scikit-learn pipeline as a feature_selection step.\n",
    "\n",
    "The class has many parameters and I invite you to look at them all but we will see the most important ones here:\n",
    "* `base_estimator`: this is the estimator used at each bootstrap. It can be a sparse estimator (lasso, logistic lasso), or an estimator giving weigth to each feature. In the first case the probability of selection will be built easily, however in the second case the user must also set a threshold below which a feature is considered not to be selected. For instance, if we use a ridge regression, a weight of 0.01 is highly negligeable compared to a weight of 50.\n",
    "* `lambda_grid`: in order to make a stability path, we need to make the regularization parameter varying. It is the list of parameter lambda to test.\n",
    "* `n_bootstraps`: This is the number of bootstraps that we need to make at each value of lambda to compute the probability of selection.\n",
    "* `artificial_type`: Type of artificial features to generate. Can either be \"random_permutation\" or \"knockoff\". If set to `None` the class will act as a classic stability selection process.\n",
    "* `artificial_proportion`: Proportion of artificial features compared to the original ones.\n",
    "* `sample_fraction`: This is the fraction of sample that will be bootstrapped at each bootstrap iteration. For instance if the dataset contains 1000 samples and `sample_fraction=0.5` then each bootstrapped dataset will contain 500 samples. \n",
    "* `replace`: Whether or not to replace samples when bootstrapping.\n",
    "* `hard_threshold`: threshold of probability above which a feature is considered to be stable. Default value is None but it must be defined if we don't use any form of synthetic feature.\n",
    "* `fdr_threshold_range`: The different threshold to test to achieve the fdr control defined above. \n",
    "* `n_jobs`: Number of CPUs to use for the parallelization of the process. Default is set to -1 (all CPUs available and should not be modified as the process can be computationnally intensive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5100699",
   "metadata": {},
   "source": [
    "## Functions and class methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6bfe3f",
   "metadata": {},
   "source": [
    "The python files contains various functions and method to help the user in visualizing the results of the stability selection:\n",
    "* `plot_stabl_path` **function**: To plot the stability path, the user can set new values for the fdr or the threshold\n",
    "* `plot_fdr_graph` **function**: When using decoy of knockoff, we might want to visualize the fdr value for the different threshold values tested.\n",
    "* `export_stabl_to_csv` **function**: to export the stability scores to csv. Can be used to see the top features probability of selections as well as to replot the graphs later ;).\n",
    "* `save_stabl_results`: **function**: to export all the graphs and csv files associated to the fitted STABL process.\n",
    "* `get_support` **class method**: To get the support of the stability selection, the user can change the value of the threshold or fdr to change the results. \n",
    "* `get_feature_names_out` **class method**: To get the name of the features that where selected by the procedure. Note that if the input don't have any names, generic ones are generated.\n",
    "\n",
    "*Note: Of course, the class inherits all the class methods of the mother classes. In this implementation we had to redefine the `get_support()` and `get_feature_names_out()` in order to give the possibility to the user to change temporarily the threshold or the fdr after the training ! Also note that it's possible to use the method of the BaseEstimator mother class `set_params` to indefinitely change the params.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da5aea",
   "metadata": {},
   "source": [
    "## STABL on a regression outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e3056",
   "metadata": {},
   "source": [
    "### Example on the proteomics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0305c5e7",
   "metadata": {},
   "source": [
    "**Defining the STABL object for regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d86887d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stabl_regression = Stabl(\n",
    "    base_estimator=clone(lasso),\n",
    "    lambda_grid={\"alpha\": np.logspace(0, 2, 30)},\n",
    "    artificial_type=\"knockoff\",\n",
    "    artificial_proportion=1,\n",
    "    n_bootstraps=1000,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bdda02",
   "metadata": {},
   "source": [
    "**Applying the preprocessing pipeline to the input file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ad70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_std = pd.DataFrame(\n",
    "    data=preprocessing.fit_transform(prot_ool),\n",
    "    index=prot_ool.index,\n",
    "    columns=preprocessing.get_feature_names_out()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ca11e",
   "metadata": {},
   "source": [
    "**Fitting the STABL object using the input file and the outcomes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stabl_regression.fit(prot_std, DOS_ool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e50a8b",
   "metadata": {},
   "source": [
    "**Visualizing the FDP+ graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fdr_graph(stabl_regression, figsize=(6, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf8e893",
   "metadata": {},
   "source": [
    "**Visualizing the STABL path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423985fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stabl_path(stabl_regression, figsize=(4,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8182007",
   "metadata": {},
   "source": [
    "**Looking at the selected features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fb385a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stabl_regression.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a24595",
   "metadata": {},
   "source": [
    "**Visualizing the selected features using the `scatterplot_features` function of the `visualization.py` file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db375ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatterplot_features(\n",
    "    list_of_features=stabl_regression.get_feature_names_out(),\n",
    "    df_X=prot_ool,\n",
    "    y=DOS_ool\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e4b515",
   "metadata": {},
   "source": [
    "## STABL on a binary classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23286347",
   "metadata": {},
   "source": [
    "### Example on the Covid proteomics file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac57a982",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_indices = prot_covid.index.intersection(covid_pos.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd54b5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "stabl_class = Stabl(\n",
    "    base_estimator=clone(logit_lasso),\n",
    "    lambda_grid={\"C\": np.linspace(0.01, 1, 30)},\n",
    "    fdr_threshold_range=np.arange(0.1, 1, 0.01),\n",
    "    n_bootstraps=1000,\n",
    "    random_state=42,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5cb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_covid_std = pd.DataFrame(\n",
    "    data=preprocessing.fit_transform(prot_covid),\n",
    "    index=prot_covid.index,\n",
    "    columns=preprocessing.get_feature_names_out()\n",
    ")\n",
    "\n",
    "prot_covid_std=prot_covid_std.loc[common_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8dadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "stabl_class.fit(prot_covid_std, covid_pos.loc[common_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25a3320",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stabl_path(stabl_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016c570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stabl_class.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa01d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fdr_graph(stabl_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8d2408",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "boxplot_features(stabl_class.get_feature_names_out(), prot_covid, covid_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a742f53b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
