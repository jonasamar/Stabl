{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "from stabl.stabl import Stabl, plot_stabl_path, plot_fdr_graph, save_stabl_results\n",
    "from stabl.preprocessing import LowInfoFilter, remove_low_info_samples\n",
    "\n",
    "%config InlineBackend.figure_formats=['retina']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stabl pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stabl.multi_omic_pipelines import multi_omic_stabl, multi_omic_stabl_cv\n",
    "from stabl.single_omic_pipelines import single_omic_stabl, single_omic_stabl_cv\n",
    "from stabl.pipelines_utils import compute_features_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19320, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"../Sample Data/Stroke/preprocessed_HT.csv\")\n",
    "dataset.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cellpop = 'Bcells*'\n",
    "\n",
    "# data1 = dataset[(dataset['population']==cellpop) & (dataset['time']=='P1')]\n",
    "# data2 = dataset[(dataset['population']==cellpop) & (dataset['time']=='P2')]\n",
    "\n",
    "    \n",
    "    \n",
    "# # Rearrangement of the data\n",
    "# dict_x1 = {}\n",
    "# dict_x2 = {}\n",
    "# dict_y = {}\n",
    "# for sample in data1['sampleID']:\n",
    "#     dict_x1[sample] = {}\n",
    "#     dict_x2[sample] = {}\n",
    "#     for feature in data1['reagent'].unique():\n",
    "#         mask1 = (data1['sampleID']==sample) & (data1['reagent']==feature)\n",
    "#         mask2 = (data2['sampleID']==sample) & (data2['reagent']==feature)\n",
    "#         dict_x1[sample][feature] = float(data1[mask1]['feature'])\n",
    "#         dict_x2[sample][feature] = float(data2[mask2]['feature'])\n",
    "#     dict_y[sample] = data1[data1['sampleID']==sample]['group'].iloc[0]\n",
    "\n",
    "# X1 = pd.DataFrame(dict_x1).T\n",
    "# X2 = pd.DataFrame(dict_x2).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampleID values : [1326 1330 1331 1337 1357 1377 1381 1400 1414 1418 1427 1428 1431 1464\n",
      " 1469 1472 1473 1475 1480 1488]\n",
      "card(sampleID) : 20\n",
      "\n",
      "population values : ['Bcells*' 'CCR2nncMC*' 'CCR2pcMC*' 'CD41hiCD61hiPLT*' 'CD4Tcm*' 'CD4Tem*'\n",
      " 'CD4Tnaive*' 'CD4Trm*' 'CD56brightCD16nNKcells*' 'CD56dimCD16pNKcells*'\n",
      " 'CD61pCD41pPLT*' 'CD62LnAgedNeutrophils*' 'CD62LpImmatureNeutrophils*'\n",
      " 'CD8Tcm*' 'CD8Tem*' 'CD8Tnaive*' 'CD8Trm*' 'gdTcells*' 'intMC*' 'mDC*'\n",
      " 'MDSC*' 'NKT*' 'pDC*' 'Th1mem*' 'Th1naive*' 'Tregmem*' 'Tregnaive*']\n",
      "card(population) : 27\n",
      "\n",
      "reagent values : ['CREB' 'STAT5' 'p38' 'STAT1' 'STAT3' 'S6' 'IkB' 'NFkB' 'ERK' 'STAT6'\n",
      " 'MAPKAPK2' 'Frequency']\n",
      "card(reagent) : 12\n",
      "\n",
      "time values : ['P1' 'P3' 'P2']\n",
      "card(time) : 3\n",
      "\n",
      "stimulation values : ['Unstim']\n",
      "card(stimulation) : 1\n",
      "\n",
      "feature values : [0.16376094 0.01940237 0.         ... 0.71118115 0.21365683 0.02493233]\n",
      "card(feature) : 15044\n",
      "\n",
      "group values : ['No' 'Yes']\n",
      "card(group) : 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in dataset.columns:\n",
    "    print(f\"{column} values : {dataset[column].unique()}\")\n",
    "    print(f\"card({column}) : {len(dataset[column].unique())}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 1 : for Bcells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampleID</th>\n",
       "      <th>population</th>\n",
       "      <th>reagent</th>\n",
       "      <th>time</th>\n",
       "      <th>stimulation</th>\n",
       "      <th>feature</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>1326</td>\n",
       "      <td>CD41hiCD61hiPLT*</td>\n",
       "      <td>CREB</td>\n",
       "      <td>P1</td>\n",
       "      <td>Unstim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>1326</td>\n",
       "      <td>CD41hiCD61hiPLT*</td>\n",
       "      <td>STAT5</td>\n",
       "      <td>P1</td>\n",
       "      <td>Unstim</td>\n",
       "      <td>0.011384</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>1326</td>\n",
       "      <td>CD41hiCD61hiPLT*</td>\n",
       "      <td>p38</td>\n",
       "      <td>P1</td>\n",
       "      <td>Unstim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>1326</td>\n",
       "      <td>CD41hiCD61hiPLT*</td>\n",
       "      <td>STAT1</td>\n",
       "      <td>P1</td>\n",
       "      <td>Unstim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>1326</td>\n",
       "      <td>CD41hiCD61hiPLT*</td>\n",
       "      <td>STAT3</td>\n",
       "      <td>P1</td>\n",
       "      <td>Unstim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2815</th>\n",
       "      <td>1488</td>\n",
       "      <td>CD41hiCD61hiPLT*</td>\n",
       "      <td>MAPKAPK2</td>\n",
       "      <td>P2</td>\n",
       "      <td>Unstim</td>\n",
       "      <td>0.172120</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2816</th>\n",
       "      <td>1488</td>\n",
       "      <td>CD41hiCD61hiPLT*</td>\n",
       "      <td>NFkB</td>\n",
       "      <td>P1</td>\n",
       "      <td>Unstim</td>\n",
       "      <td>0.135898</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2817</th>\n",
       "      <td>1488</td>\n",
       "      <td>CD41hiCD61hiPLT*</td>\n",
       "      <td>ERK</td>\n",
       "      <td>P1</td>\n",
       "      <td>Unstim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2818</th>\n",
       "      <td>1488</td>\n",
       "      <td>CD41hiCD61hiPLT*</td>\n",
       "      <td>STAT6</td>\n",
       "      <td>P1</td>\n",
       "      <td>Unstim</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>1488</td>\n",
       "      <td>CD41hiCD61hiPLT*</td>\n",
       "      <td>MAPKAPK2</td>\n",
       "      <td>P1</td>\n",
       "      <td>Unstim</td>\n",
       "      <td>0.074353</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sampleID        population   reagent time stimulation   feature group\n",
       "2160      1326  CD41hiCD61hiPLT*      CREB   P1      Unstim  0.000000     0\n",
       "2161      1326  CD41hiCD61hiPLT*     STAT5   P1      Unstim  0.011384     0\n",
       "2162      1326  CD41hiCD61hiPLT*       p38   P1      Unstim  0.000000     0\n",
       "2163      1326  CD41hiCD61hiPLT*     STAT1   P1      Unstim  0.000000     0\n",
       "2164      1326  CD41hiCD61hiPLT*     STAT3   P1      Unstim  0.000000     0\n",
       "...        ...               ...       ...  ...         ...       ...   ...\n",
       "2815      1488  CD41hiCD61hiPLT*  MAPKAPK2   P2      Unstim  0.172120     1\n",
       "2816      1488  CD41hiCD61hiPLT*      NFkB   P1      Unstim  0.135898     1\n",
       "2817      1488  CD41hiCD61hiPLT*       ERK   P1      Unstim  0.000000     1\n",
       "2818      1488  CD41hiCD61hiPLT*     STAT6   P1      Unstim  0.000000     1\n",
       "2819      1488  CD41hiCD61hiPLT*  MAPKAPK2   P1      Unstim  0.074353     1\n",
       "\n",
       "[660 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset[dataset['population']=='CD41hiCD61hiPLT*']\n",
    "dataset['group'][dataset['group']=='No']=0\n",
    "dataset['group'][dataset['group']=='Yes']=1\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('./Data', 'P3', 'CD41hiCD61hiPLT')\n",
    "os.makedirs(data_path, exist_ok=True)\n",
    "os.makedirs('./Results', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "P3_dataset = dataset[dataset['time']=='P3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "P3_dict_x = {}\n",
    "P3_dict_y = {}\n",
    "for sample in dataset['sampleID']:\n",
    "    P3_dict_x[sample] = {}\n",
    "    for feature in dataset['reagent'].unique():\n",
    "        mask = (P3_dataset['sampleID']==sample) & (P3_dataset['reagent']==feature)\n",
    "        P3_dict_x[sample][feature] = float(P3_dataset[mask]['feature'])\n",
    "    P3_dict_y[sample] = P3_dataset[P3_dataset['sampleID']==sample]['group'].iloc[0]\n",
    "        \n",
    "pd.DataFrame(P3_dict_x).T.to_csv(Path(data_path, \"X.csv\"), index=True)\n",
    "pd.DataFrame([P3_dict_y]).T.to_csv(Path(data_path, \"y.csv\"), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(Path(data_path, \"X.csv\"), index_col=0)\n",
    "y = pd.read_csv(Path(data_path, \"y.csv\"), index_col=0).iloc[:, 0]\n",
    "y.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result folder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder = \"./Results/P3/CD41hiCD61hiPLT\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single-omic Training-CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stabl = Stabl(\n",
    "    lambda_grid=np.linspace(0.01, 5, 10),\n",
    "    n_bootstraps=1000,\n",
    "    artificial_type=\"random_permutation\",\n",
    "    replace=False,\n",
    "    fdr_threshold_range=np.arange(0.1, 1, 0.01),\n",
    "    sample_fraction=.5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "stability_selection = clone(stabl).set_params(hard_threshold=.1, artificial_type = None)\n",
    "\n",
    "#outer_splitter = LeaveOneOut()\n",
    "#outer_splitter = RepeatedStratifiedKFold(n_splits=len(X), n_repeats=20, random_state=42)\n",
    "outer_splitter = RepeatedKFold(n_splits=len(X), n_repeats=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************** Iteration 1 over 200 ***************************** \n",
      "\n",
      "19 train samples, 1 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               11<00:00,  5.23s/it]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STABL finished (19 samples); 0 features selected\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               49<00:00,  4.87s/it]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "This fold: 0 features selected for STABL\n",
      "This fold: 1 features selected for SS 03\n",
      "This fold: 1 features selected for SS 05\n",
      "This fold: 1 features selected for SS 08\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "***************************** Iteration 2 over 200 ***************************** \n",
      "\n",
      "19 train samples, 1 test samples\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No feature in X meets the variance threshold 0.01000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mstabl\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msingle_omic_pipelines\u001b[39;00m \u001b[39mimport\u001b[39;00m single_omic_stabl_cv\n\u001b[0;32m----> 3\u001b[0m predictions_dict \u001b[39m=\u001b[39m single_omic_stabl_cv(\n\u001b[1;32m      4\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m      5\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m      6\u001b[0m     outer_splitter\u001b[39m=\u001b[39;49mouter_splitter,\n\u001b[1;32m      7\u001b[0m     stabl\u001b[39m=\u001b[39;49mstabl,\n\u001b[1;32m      8\u001b[0m     stability_selection\u001b[39m=\u001b[39;49mstability_selection,\n\u001b[1;32m      9\u001b[0m     task_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbinary\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     save_path\u001b[39m=\u001b[39;49mresult_folder,\n\u001b[1;32m     11\u001b[0m     outer_groups\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/Stabl/.venv/lib/python3.9/site-packages/stabl/single_omic_pipelines.py:130\u001b[0m, in \u001b[0;36msingle_omic_stabl_cv\u001b[0;34m(X, y, outer_splitter, stabl, stability_selection, task_type, save_path, outer_groups)\u001b[0m\n\u001b[1;32m    126\u001b[0m X_tmp \u001b[39m=\u001b[39m remove_low_info_samples(X_tmp)\n\u001b[1;32m    127\u001b[0m y_tmp \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mloc[X_tmp\u001b[39m.\u001b[39mindex]\n\u001b[1;32m    129\u001b[0m X_tmp_std \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(\n\u001b[0;32m--> 130\u001b[0m     data\u001b[39m=\u001b[39mpreprocessing\u001b[39m.\u001b[39;49mfit_transform(X_tmp),\n\u001b[1;32m    131\u001b[0m     index\u001b[39m=\u001b[39mX_tmp\u001b[39m.\u001b[39mindex,\n\u001b[1;32m    132\u001b[0m     columns\u001b[39m=\u001b[39mpreprocessing\u001b[39m.\u001b[39mget_feature_names_out()\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    135\u001b[0m \u001b[39m# __STABL__\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39mif\u001b[39;00m task_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Stabl/.venv/lib/python3.9/site-packages/sklearn/pipeline.py:437\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \n\u001b[1;32m    412\u001b[0m \u001b[39mFits all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[39m    Transformed samples.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    436\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 437\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    439\u001b[0m last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\n\u001b[1;32m    440\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n",
      "File \u001b[0;32m~/Stabl/.venv/lib/python3.9/site-packages/sklearn/pipeline.py:359\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    357\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    358\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 359\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    360\u001b[0m     cloned_transformer,\n\u001b[1;32m    361\u001b[0m     X,\n\u001b[1;32m    362\u001b[0m     y,\n\u001b[1;32m    363\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    364\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    365\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    366\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    367\u001b[0m )\n\u001b[1;32m    368\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/Stabl/.venv/lib/python3.9/site-packages/joblib/memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Stabl/.venv/lib/python3.9/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/Stabl/.venv/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/Stabl/.venv/lib/python3.9/site-packages/sklearn/base.py:878\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    877\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    879\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    880\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    881\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/Stabl/.venv/lib/python3.9/site-packages/sklearn/feature_selection/_variance_threshold.py:125\u001b[0m, in \u001b[0;36mVarianceThreshold.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    124\u001b[0m         msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m (X contains only one sample)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthreshold))\n\u001b[1;32m    127\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: No feature in X meets the variance threshold 0.01000"
     ]
    }
   ],
   "source": [
    "from stabl.single_omic_pipelines import single_omic_stabl_cv\n",
    "\n",
    "predictions_dict = single_omic_stabl_cv(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    outer_splitter=outer_splitter,\n",
    "    stabl=stabl,\n",
    "    stability_selection=stability_selection,\n",
    "    task_type=\"binary\",\n",
    "    save_path=result_folder,\n",
    "    outer_groups=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_dict = dict()\n",
    "for model in [\"STABL\", \"Lasso\", \"Lasso 1SE\", \"ElasticNet\", \"SS 03\", \"SS 05\", \"SS 08\"]:\n",
    "    path = Path(result_folder, \"Training-Validation\", f\"{model} coefficients.csv\")\n",
    "    try:\n",
    "        selected_features_dict[model] = list(pd.read_csv(path, index_col=0).iloc[:, 0].index)\n",
    "    except:\n",
    "        selected_features_dict[model] = []\n",
    "        \n",
    "features_table = compute_features_table(\n",
    "    selected_features_dict,\n",
    "    X_train=X,\n",
    "    y_train=y,\n",
    "    X_test=None,\n",
    "    y_test=None,\n",
    "    task_type=\"binary\")\n",
    "\n",
    "os.makedirs(Path(result_folder, \"Training-Validation\"))\n",
    "features_table.to_csv(Path(result_folder, \"Training-Validation\", \"Table of features.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "\n",
    "Spearmancorr = {}\n",
    "\n",
    "features = X.columns\n",
    "\n",
    "for feature in features:\n",
    "    \n",
    "    corr, pval = spearmanr(X[feature], y)\n",
    "    Spearmancorr[feature] = [corr, pval]\n",
    "\n",
    "SpearmanPvalue = pd.DataFrame(Spearmancorr).T\n",
    "SpearmanPvalue.columns = ['Spearman corr', 'pvalue']\n",
    "SpearmanPvalue.sort_values('pvalue', inplace=True)\n",
    "SpearmanPvalue.to_csv(Path(result_folder, 'Summary', 'SpearmanCorrelationsPval.csv'), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stabl.visualization import boxplot_features\n",
    "\n",
    "os.makedirs(Path(result_folder, 'Univariate'))\n",
    "\n",
    "boxplot_features(\n",
    "        SpearmanPvalue[:5].index,\n",
    "        X,\n",
    "        y,\n",
    "        show_fig=False,\n",
    "        export_file=True,\n",
    "        path=Path(result_folder, 'Univariate'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rearrangement of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Source and destination paths\n",
    "for model in [\"STABL\", \"Lasso\", \"Lasso 1SE\", \"ElasticNet\", \"SS 03\", \"SS 05\", \"SS 08\"]:\n",
    "    src_folder = Path(result_folder, 'Training CV', model)\n",
    "    dst_folder = Path(result_folder, 'Summary')\n",
    "\n",
    "    # Loop over the files in the source folder\n",
    "    for filename in os.listdir(src_folder):\n",
    "        if \"Boxplot\" in filename:\n",
    "            src_file = os.path.join(src_folder, filename)\n",
    "            dst_file = os.path.join(dst_folder, filename)\n",
    "            shutil.copy(src_file, dst_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "import csv\n",
    "\n",
    "def get_pvalue_from_Boxplot(model):\n",
    "    reader = PdfReader(Path(result_folder, 'Summary', model + ' Boxplot of median predictions.pdf'))         \n",
    "    # getting a specific page from the pdf file\n",
    "    page = reader.pages[0]\n",
    "\n",
    "    # extracting text from page\n",
    "    text = page.extract_text()\n",
    "    start_index = text.find('U-test pvalue = ') + len('U-test pvalue = ')\n",
    "    end_index = text.find('\\n', start_index)\n",
    "    return text[start_index:end_index]\n",
    "\n",
    "# Modifying a csv file to add the U-test pvalue\n",
    "with open(Path(result_folder, 'Summary', 'Scores training CV.csv', newline='')) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    with open(Path(result_folder, 'Summary', 'Scores training CV (2).csv'), mode='w', newline='') as new_csvfile:\n",
    "        writer = csv.writer(new_csvfile)\n",
    "        for i, row in enumerate(reader):\n",
    "            # modified values\n",
    "            if i == 0:\n",
    "                row.append('U-test pvalue')\n",
    "            else:\n",
    "                model = row[0]\n",
    "                row.append(get_pvalue_from_Boxplot(model))\n",
    "            writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
